<!DOCTYPE html>
<html>
  <head>
    <title>The Lift Project - Performance Portable Code Generation via Rewrite Rules</title>
    <meta charset="utf-8">
    <style>
      @import url(../template/lift.css);
      @import url(../template/glasgow.css);
      @import url(../template/print.css);
    </style>
  </head>
  <body>
    <textarea id="source">

name: title
background-image: url(../template/images/Title16x9.jpg)
class: title-slide
count: false

# The .lift[Lift] Project
## Performance Portable Code Generation via Rewrite Rules

### Michel Steuwer .smaller[| [http://michel.steuwer.info](http://michel.steuwer.info/) | [michel.steuwer@glasgow.ac.uk](mailto:michel.steuwer@glasgow.ac.uk)]

---
class: split-40

# What is the problem .lift[Lift] tries to tackle?

.left-column[
- Parallel processors everywhere

- Many different types:<br/>
    CPUs, GPUs, FPGAs, ...

- Parallel programming is hard

- Optimising is even harder

- **How do we write efficient software for all these devices?**
]

<div style="width: 400px; position: absolute; top: 150px; left: 560px">
    <img style="vertical-align:middle" src="images/cpu.png" width="80%"/>
    <strong>CPUs</strong>
</div>

<div style="width: 500px; position: absolute; top: 220px; left: 640px;">
    <img style="vertical-align:middle" src="images/gpu.png" width="80%"/>
    <strong style="margin-left: -30px;">GPUs</strong>
</div>

<div style="width: 200px; position: absolute; top: 375px; left: 500px;">
    <img style="vertical-align:middle" src="images/phi.png" width="100%"/>
    <center><strong>Accelerator</strong></center>
</div>

<div style="width: 150px; position: absolute; top: 395px; left: 740px;">
    <img style="vertical-align:middle" src="images/fpga.png" width="100%"/>
    <center><strong>FPGA</strong></center>
</div>

<div style="width: 150px; position: absolute; top: 375px; left: 960px;">
    <img style="vertical-align:middle" src="images/tpu.png" width="100%"/>
    <center><strong>TPU</strong></center>
</div>

<div style="width: 200px; position: absolute; top: 550px; left: 360px;">
    <img style="vertical-align:middle" src="images/hpu.png" width="100%"/>
    <center><strong>HPU</strong></center>
</div>

<div style="width: 200px; position: absolute; top: 560px; left: 600px;">
    <img style="vertical-align:middle" src="images/brainwave.png" width="100%"/>
    <center><strong>Brainwave</strong></center>
</div>

<div style="width: 150px; position: absolute; top: 540px; left: 850px;">
    <center><img style="vertical-align:middle" src="images/neuralEngine.png" width="75%"/></center>
    <center><strong>Neural Engine</strong></center>
</div>


---
# Case Study: Parallel Reduction in OpenCL

- Summing up all values of an array

- Comparison of 7 implementations by Nvidia

- Investigating complexity and efficiency of optimisations

.box-70[
<img src="images/reduction.pdf" width="100%" />
]

---
# 1. Version: .smaller[Unoptimised Reduction Implementation]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local float* l_data) {
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_global_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  barrier(CLK_LOCAL_MEM_FENCE);

  for (unsigned int s=1; s < get_local_size(0); s *= 2) {
      if ((tid % (2*s)) == 0) {
          l_data[tid] += l_data[tid + s];
      }
      barrier(CLK_LOCAL_MEM_FENCE);
  }

  if (tid == 0) g_odata[get_group_id(0)] = l_data[0];
}
```
]

---
# 2. Version: .smaller[Avoid Divergent Branching]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local float* l_data) {
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_global_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  barrier(CLK_LOCAL_MEM_FENCE);

  for (unsigned int s=1; s < get_local_size(0); s *= 2) {
      `int index = 2 * s * tid;`
      if (`index < get_local_size(0)`) {
          l_data[`index`] += l_data[`index` + s];
      }
      barrier(CLK_LOCAL_MEM_FENCE);
  }

  if (tid == 0) g_odata[get_group_id(0)] = l_data[0];
}
```
]

---
# 3. Version: .smaller[Avoid Interleaved Addressing]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local float* l_data) {
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_global_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  barrier(CLK_LOCAL_MEM_FENCE);

  for (`unsigned int s=get_local_size(0)/2; s > 0; s >>= 1`) {
      if (`tid < s`) {
          l_data[`tid`] += l_data[`tid`+ s];
      }
      barrier(CLK_LOCAL_MEM_FENCE);
  }

  if (tid == 0) g_odata[get_group_id(0)] = l_data[0];
}
```
]

---
# 4. Version: .smaller[Increase Comp. Intensity per Work-Item]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local float* l_data) {
  unsigned int tid = get_local_id(0);
  `unsigned int i   = get_group_id(0) * (get_local_size(0)*2)`
                                     `+ get_local_id(0);`
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  // perform first addition during loading
  `if (i + get_local_size(0) < n)`
    `l_data[tid] += g_idata[i + get_local_size(0)];`
  barrier(CLK_LOCAL_MEM_FENCE);

  for (unsigned int s=get_local_size(0)/2; s > 0; s >>= 1) {
      if (tid < s) {
          l_data[tid] += l_data[tid+ s];
      }
      barrier(CLK_LOCAL_MEM_FENCE);
  }

  if (tid == 0) g_odata[get_group_id(0)] = l_data[0];
}
```
]

---
# 5. Version: .smaller[Avoid Synchronisation inside a Warp]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local `volatile` float* l_data){
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_group_id(0) * (get_local_size(0)*2)
                                     + get_local_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  if (i + get_local_size(0) < n)
    l_data[tid] += g_idata[i + get_local_size(0)];
  barrier(CLK_LOCAL_MEM_FENCE);
  `#pragma unroll 1`
  for (unsigned int s=get_local_size(0)/2; s > `32`; s >>= 1) {
      if (tid < s) { l_data[tid] += l_data[tid+ s]; }
      barrier(CLK_LOCAL_MEM_FENCE); }
  // this is not portable OpenCL code!
  `if (tid < 32) {`
  `  if (WG_SIZE >= 64) { l_data[tid] += l_data[tid+32]; }`
  `  if (WG_SIZE >= 32) { l_data[tid] += l_data[tid+16]; }`
  `  if (WG_SIZE >= 16) { l_data[tid] += l_data[tid+ 8]; }`
  `  if (WG_SIZE >=  8) { l_data[tid] += l_data[tid+ 4]; }`
  `  if (WG_SIZE >=  4) { l_data[tid] += l_data[tid+ 2]; }`
  `  if (WG_SIZE >=  2) { l_data[tid] += l_data[tid+ 1]; } }`
  if (tid == 0) g_odata[get_group_id(0)] = l_data[0];
}
```
]

---
# 6. Version: .smaller[Complete Loop Unrolling]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local volatile float* l_data){
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_group_id(0) * (get_local_size(0)*2)
                                     + get_local_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  if (i + get_local_size(0) < n)
    l_data[tid] += g_idata[i + get_local_size(0)];
  barrier(CLK_LOCAL_MEM_FENCE);
  `if (WG_SIZE >= 256) {`
  `    if (tid < 128) { l_data[tid] += l_data[tid+128]; }`
  `    barrier(CLK_LOCAL_MEM_FENCE); }`
  `if (WG_SIZE >= 128) {`
  `    if (tid < 64) { l_data[tid] += l_data[tid+ 64]; }`
  `    barrier(CLK_LOCAL_MEM_FENCE); }`
  if (tid < 32) {
    if (WG_SIZE >= 64) { l_data[tid] += l_data[tid+32]; }
    if (WG_SIZE >= 32) { l_data[tid] += l_data[tid+16]; }
    if (WG_SIZE >= 16) { l_data[tid] += l_data[tid+ 8]; }
    if (WG_SIZE >=  8) { l_data[tid] += l_data[tid+ 4]; }
    if (WG_SIZE >=  4) { l_data[tid] += l_data[tid+ 2]; }
    if (WG_SIZE >=  2) { l_data[tid] += l_data[tid+ 1]; } }
  if (tid == 0) g_odata[get_group_id(0)] = l_data[0]; }
```
]

---
# 7. Version: .smaller[Fully Optimised Implementation]

.box-70[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local volatile float* l_data){
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_group_id(0) * (get_local_size(0)*2)
                                     + get_local_id(0);
  `unsigned int gridSize = WG_SIZE * get_num_groups(0);`
  `l_data[tid] = 0;`
  `while (i < n) { l_data[tid] += g_idata[i];`
  `                if (i + WG_SIZE < n)`
  `                  l_data[tid] += g_idata[i+WG_SIZE];`
  `                i += gridSize; }`
  barrier(CLK_LOCAL_MEM_FENCE);
  if (WG_SIZE >= 256) {
      if (tid < 128) { l_data[tid] += l_data[tid+128]; }
      barrier(CLK_LOCAL_MEM_FENCE); }
  if (WG_SIZE >= 128) {
      if (tid < 64) { l_data[tid] += l_data[tid+ 64]; }
      barrier(CLK_LOCAL_MEM_FENCE); }
  if (tid < 32) {
    if (WG_SIZE >= 64) { l_data[tid] += l_data[tid+32]; }
    if (WG_SIZE >= 32) { l_data[tid] += l_data[tid+16]; }
    if (WG_SIZE >= 16) { l_data[tid] += l_data[tid+ 8]; }
    if (WG_SIZE >=  8) { l_data[tid] += l_data[tid+ 4]; }
    if (WG_SIZE >=  4) { l_data[tid] += l_data[tid+ 2]; }
    if (WG_SIZE >=  2) { l_data[tid] += l_data[tid+ 1]; } }
  if (tid == 0) g_odata[get_group_id(0)] = l_data[0]; }
```
]

---
class: split-50

# Reduction Case Study Conclusions

.left-column[
- Programming and optimising OpenCL is complex
    - Understanding of target hardware required

- Program changes are not obvious

- Why are we doing this? Is it woth it? ...
]


.right-column[
.box-90[.small[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local float* l_data) {
  unsigned int tid = get_local_id(0);
  unsigned int i   = get_global_id(0);
  l_data[tid] = (i < n) ? g_idata[i] : 0;
  barrier(CLK_LOCAL_MEM_FENCE);
  for (unsigned int s=1; s < get_local_size(0); s *= 2) {
      if ((tid % (2*s)) == 0)
          l_data[tid] += l_data[tid + s];
      barrier(CLK_LOCAL_MEM_FENCE); }
  if (tid == 0) g_odata[get_group_id(0)] = l_data[0]; }
```
]]
.smaller[.center[↑ Unoptimised ↑ &emsp; vs. &emsp; ↓ Fully Optimised ↓]]
.box-90[.small[
```
kernel void reduce(global float* g_idata, global float* g_odata,
                   unsigned int n, local volatile float* l_data) {
  unsigned int tid = get_local_id(0);
  unsigned int i = get_group_id(0) * (get_local_size(0)*2) + get_local_id(0);
  unsigned int gridSize = WG_SIZE * get_num_groups(0);
  l_data[tid] = 0;
  while (i < n) { l_data[tid] += g_idata[i];
                  if (i + WG_SIZE < n) l_data[tid] += g_idata[i+WG_SIZE];
                  i += gridSize; }
  barrier(CLK_LOCAL_MEM_FENCE);
  if (WG_SIZE >= 256) {
      if (tid < 128) { l_data[tid] += l_data[tid+128]; }
      barrier(CLK_LOCAL_MEM_FENCE); }
  if (WG_SIZE >= 128) {
      if (tid < 64) { l_data[tid] += l_data[tid+ 64]; }
      barrier(CLK_LOCAL_MEM_FENCE); }
  if (tid < 32) {
    if (WG_SIZE >= 64) { l_data[tid] += l_data[tid+32]; }
    if (WG_SIZE >= 32) { l_data[tid] += l_data[tid+16]; }
    if (WG_SIZE >= 16) { l_data[tid] += l_data[tid+ 8]; }
    if (WG_SIZE >=  8) { l_data[tid] += l_data[tid+ 4]; }
    if (WG_SIZE >=  4) { l_data[tid] += l_data[tid+ 2]; }
    if (WG_SIZE >=  2) { l_data[tid] += l_data[tid+ 1]; } }
  if (tid == 0) g_odata[get_group_id(0)] = l_data[0]; }
```
]]
]

---
# Performance Results Nvidia

.box-50[
<img src="images/nvidiaReduction.pdf" width="100%" />
]

- ... Yes! Optimising improves performance by a factor of **10**!

- Optimising is important, but ...

---
class: split-50

# Performance Results AMD and Intel

.left-column[
.box-90[
<img src="images/amdReduction.pdf" width="100%" />
]
]

.right-column[
.box-90[
<img src="images/intelReduction.pdf" width="100%" />
]
]

.clear-columns[]

- ... unfortunatley, optimisations in OpenCL are not portable!

- Costly optimisation process required for every new device.

- **Challenge**: how to achieve *performance portability*?

---

name: closing
background-image: url(../template/images/Closing16x9.jpg)
class: title-slide, text-white
count: false

# The .lift[Lift] Project
## Performance Portable Code Generation via Rewrite Rules

### Michel Steuwer .smaller[| [http://michel.steuwer.info](http://michel.steuwer.info/) | [michel.steuwer@glasgow.ac.uk](mailto:michel.steuwer@glasgow.ac.uk)]

.center-bottom[.big[[http://www.lift-project.org/](http://www.lift-project.org/)]]

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
          ratio: '16:9',
          highlightLanguage: 'c',
          highlightStyle: 'monokai', // light: 'idea', dark: 'monokai'
          highlightLines: true,
          highlightSpans: true
          });
    </script>
  </body>
</html>